{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4206249-e1f6-460f-8e54-6a78d96a60b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as ds\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cccfba-1c08-4d15-a14b-002a43ad5cad",
   "metadata": {},
   "source": [
    "## 7.7 다층 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b722637-883a-44b5-8df6-851162d4f61b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23d4490d-5cff-489f-ad67-17f20544aaf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = ds.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12a9c828-41eb-424f-b316-81a25ce4e88e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 - 2s - loss: 0.0856 - accuracy: 0.2789 - val_loss: 0.0822 - val_accuracy: 0.3831 - 2s/epoch - 4ms/step\n",
      "Epoch 2/50\n",
      "469/469 - 1s - loss: 0.0786 - accuracy: 0.4610 - val_loss: 0.0745 - val_accuracy: 0.5344 - 1s/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "469/469 - 1s - loss: 0.0707 - accuracy: 0.5657 - val_loss: 0.0666 - val_accuracy: 0.6042 - 1s/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "469/469 - 1s - loss: 0.0635 - accuracy: 0.6206 - val_loss: 0.0598 - val_accuracy: 0.6498 - 1s/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "469/469 - 1s - loss: 0.0574 - accuracy: 0.6635 - val_loss: 0.0542 - val_accuracy: 0.6907 - 1s/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "469/469 - 1s - loss: 0.0525 - accuracy: 0.7001 - val_loss: 0.0496 - val_accuracy: 0.7232 - 1s/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "469/469 - 1s - loss: 0.0484 - accuracy: 0.7265 - val_loss: 0.0458 - val_accuracy: 0.7464 - 1s/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "469/469 - 1s - loss: 0.0450 - accuracy: 0.7472 - val_loss: 0.0425 - val_accuracy: 0.7662 - 1s/epoch - 3ms/step\n",
      "Epoch 9/50\n",
      "469/469 - 1s - loss: 0.0421 - accuracy: 0.7679 - val_loss: 0.0398 - val_accuracy: 0.7906 - 1s/epoch - 3ms/step\n",
      "Epoch 10/50\n",
      "469/469 - 1s - loss: 0.0395 - accuracy: 0.7877 - val_loss: 0.0373 - val_accuracy: 0.8090 - 1s/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "469/469 - 1s - loss: 0.0373 - accuracy: 0.8041 - val_loss: 0.0352 - val_accuracy: 0.8212 - 1s/epoch - 3ms/step\n",
      "Epoch 12/50\n",
      "469/469 - 1s - loss: 0.0354 - accuracy: 0.8151 - val_loss: 0.0334 - val_accuracy: 0.8319 - 1s/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "469/469 - 1s - loss: 0.0338 - accuracy: 0.8231 - val_loss: 0.0319 - val_accuracy: 0.8387 - 1s/epoch - 3ms/step\n",
      "Epoch 14/50\n",
      "469/469 - 1s - loss: 0.0324 - accuracy: 0.8301 - val_loss: 0.0306 - val_accuracy: 0.8441 - 1s/epoch - 3ms/step\n",
      "Epoch 15/50\n",
      "469/469 - 1s - loss: 0.0311 - accuracy: 0.8357 - val_loss: 0.0294 - val_accuracy: 0.8491 - 1s/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "469/469 - 1s - loss: 0.0300 - accuracy: 0.8408 - val_loss: 0.0284 - val_accuracy: 0.8523 - 1s/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "469/469 - 1s - loss: 0.0291 - accuracy: 0.8446 - val_loss: 0.0275 - val_accuracy: 0.8554 - 1s/epoch - 3ms/step\n",
      "Epoch 18/50\n",
      "469/469 - 1s - loss: 0.0282 - accuracy: 0.8482 - val_loss: 0.0267 - val_accuracy: 0.8584 - 1s/epoch - 3ms/step\n",
      "Epoch 19/50\n",
      "469/469 - 1s - loss: 0.0275 - accuracy: 0.8509 - val_loss: 0.0260 - val_accuracy: 0.8621 - 1s/epoch - 3ms/step\n",
      "Epoch 20/50\n",
      "469/469 - 1s - loss: 0.0268 - accuracy: 0.8543 - val_loss: 0.0253 - val_accuracy: 0.8644 - 1s/epoch - 3ms/step\n",
      "Epoch 21/50\n",
      "469/469 - 1s - loss: 0.0262 - accuracy: 0.8564 - val_loss: 0.0248 - val_accuracy: 0.8664 - 1s/epoch - 3ms/step\n",
      "Epoch 22/50\n",
      "469/469 - 1s - loss: 0.0256 - accuracy: 0.8592 - val_loss: 0.0242 - val_accuracy: 0.8680 - 1s/epoch - 3ms/step\n",
      "Epoch 23/50\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.8612 - val_loss: 0.0237 - val_accuracy: 0.8701 - 1s/epoch - 3ms/step\n",
      "Epoch 24/50\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.8630 - val_loss: 0.0233 - val_accuracy: 0.8722 - 1s/epoch - 3ms/step\n",
      "Epoch 25/50\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.8650 - val_loss: 0.0229 - val_accuracy: 0.8730 - 1s/epoch - 3ms/step\n",
      "Epoch 26/50\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.8665 - val_loss: 0.0225 - val_accuracy: 0.8747 - 1s/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.8681 - val_loss: 0.0222 - val_accuracy: 0.8758 - 1s/epoch - 3ms/step\n",
      "Epoch 28/50\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.8694 - val_loss: 0.0218 - val_accuracy: 0.8771 - 1s/epoch - 3ms/step\n",
      "Epoch 29/50\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.8708 - val_loss: 0.0215 - val_accuracy: 0.8782 - 1s/epoch - 3ms/step\n",
      "Epoch 30/50\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.8722 - val_loss: 0.0212 - val_accuracy: 0.8795 - 1s/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.8730 - val_loss: 0.0210 - val_accuracy: 0.8809 - 1s/epoch - 3ms/step\n",
      "Epoch 32/50\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.8742 - val_loss: 0.0207 - val_accuracy: 0.8819 - 1s/epoch - 3ms/step\n",
      "Epoch 33/50\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.8752 - val_loss: 0.0205 - val_accuracy: 0.8837 - 1s/epoch - 3ms/step\n",
      "Epoch 34/50\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.8762 - val_loss: 0.0203 - val_accuracy: 0.8847 - 1s/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.8773 - val_loss: 0.0200 - val_accuracy: 0.8852 - 1s/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "469/469 - 1s - loss: 0.0210 - accuracy: 0.8784 - val_loss: 0.0198 - val_accuracy: 0.8861 - 1s/epoch - 3ms/step\n",
      "Epoch 37/50\n",
      "469/469 - 1s - loss: 0.0208 - accuracy: 0.8793 - val_loss: 0.0197 - val_accuracy: 0.8867 - 1s/epoch - 3ms/step\n",
      "Epoch 38/50\n",
      "469/469 - 1s - loss: 0.0206 - accuracy: 0.8801 - val_loss: 0.0195 - val_accuracy: 0.8877 - 1s/epoch - 3ms/step\n",
      "Epoch 39/50\n",
      "469/469 - 1s - loss: 0.0204 - accuracy: 0.8809 - val_loss: 0.0193 - val_accuracy: 0.8885 - 1s/epoch - 3ms/step\n",
      "Epoch 40/50\n",
      "469/469 - 1s - loss: 0.0202 - accuracy: 0.8818 - val_loss: 0.0191 - val_accuracy: 0.8891 - 1s/epoch - 3ms/step\n",
      "Epoch 41/50\n",
      "469/469 - 1s - loss: 0.0200 - accuracy: 0.8824 - val_loss: 0.0190 - val_accuracy: 0.8901 - 1s/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "469/469 - 1s - loss: 0.0199 - accuracy: 0.8833 - val_loss: 0.0188 - val_accuracy: 0.8906 - 1s/epoch - 3ms/step\n",
      "Epoch 43/50\n",
      "469/469 - 1s - loss: 0.0197 - accuracy: 0.8836 - val_loss: 0.0187 - val_accuracy: 0.8911 - 1s/epoch - 3ms/step\n",
      "Epoch 44/50\n",
      "469/469 - 1s - loss: 0.0196 - accuracy: 0.8842 - val_loss: 0.0185 - val_accuracy: 0.8914 - 1s/epoch - 3ms/step\n",
      "Epoch 45/50\n",
      "469/469 - 1s - loss: 0.0194 - accuracy: 0.8849 - val_loss: 0.0184 - val_accuracy: 0.8919 - 1s/epoch - 3ms/step\n",
      "Epoch 46/50\n",
      "469/469 - 1s - loss: 0.0193 - accuracy: 0.8856 - val_loss: 0.0183 - val_accuracy: 0.8925 - 1s/epoch - 3ms/step\n",
      "Epoch 47/50\n",
      "469/469 - 1s - loss: 0.0192 - accuracy: 0.8865 - val_loss: 0.0181 - val_accuracy: 0.8928 - 1s/epoch - 3ms/step\n",
      "Epoch 48/50\n",
      "469/469 - 1s - loss: 0.0190 - accuracy: 0.8869 - val_loss: 0.0180 - val_accuracy: 0.8932 - 1s/epoch - 3ms/step\n",
      "Epoch 49/50\n",
      "469/469 - 1s - loss: 0.0189 - accuracy: 0.8874 - val_loss: 0.0179 - val_accuracy: 0.8937 - 1s/epoch - 3ms/step\n",
      "Epoch 50/50\n",
      "469/469 - 1s - loss: 0.0188 - accuracy: 0.8879 - val_loss: 0.0178 - val_accuracy: 0.8942 - 1s/epoch - 3ms/step\n",
      "accuracy = 89.42000269889832\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential([\n",
    "    Dense(units=512, activation=\"tanh\", input_shape=(784,)),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "log_dir = \"logs/fit/mlp_SGD\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "mlp.compile(loss=\"MSE\", optimizer=SGD(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "mlp.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test), verbose=2,\n",
    "       callbacks=[tensorboard_callback])\n",
    "\n",
    "res = mlp.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"accuracy =\", res[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f779d1-9aa2-482b-b3ca-7056a964b302",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 - 3s - loss: 0.0149 - accuracy: 0.9015 - val_loss: 0.0101 - val_accuracy: 0.9333 - 3s/epoch - 6ms/step\n",
      "Epoch 2/50\n",
      "469/469 - 3s - loss: 0.0087 - accuracy: 0.9438 - val_loss: 0.0071 - val_accuracy: 0.9546 - 3s/epoch - 5ms/step\n",
      "Epoch 3/50\n",
      "469/469 - 3s - loss: 0.0064 - accuracy: 0.9594 - val_loss: 0.0058 - val_accuracy: 0.9640 - 3s/epoch - 6ms/step\n",
      "Epoch 4/50\n",
      "469/469 - 3s - loss: 0.0049 - accuracy: 0.9693 - val_loss: 0.0054 - val_accuracy: 0.9659 - 3s/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "469/469 - 3s - loss: 0.0040 - accuracy: 0.9758 - val_loss: 0.0047 - val_accuracy: 0.9701 - 3s/epoch - 6ms/step\n",
      "Epoch 6/50\n",
      "469/469 - 3s - loss: 0.0033 - accuracy: 0.9804 - val_loss: 0.0044 - val_accuracy: 0.9710 - 3s/epoch - 6ms/step\n",
      "Epoch 7/50\n",
      "469/469 - 3s - loss: 0.0027 - accuracy: 0.9840 - val_loss: 0.0038 - val_accuracy: 0.9743 - 3s/epoch - 6ms/step\n",
      "Epoch 8/50\n",
      "469/469 - 3s - loss: 0.0023 - accuracy: 0.9866 - val_loss: 0.0035 - val_accuracy: 0.9774 - 3s/epoch - 5ms/step\n",
      "Epoch 9/50\n",
      "469/469 - 3s - loss: 0.0019 - accuracy: 0.9893 - val_loss: 0.0035 - val_accuracy: 0.9780 - 3s/epoch - 6ms/step\n",
      "Epoch 10/50\n",
      "469/469 - 3s - loss: 0.0017 - accuracy: 0.9908 - val_loss: 0.0035 - val_accuracy: 0.9768 - 3s/epoch - 6ms/step\n",
      "Epoch 11/50\n",
      "469/469 - 3s - loss: 0.0014 - accuracy: 0.9924 - val_loss: 0.0037 - val_accuracy: 0.9763 - 3s/epoch - 5ms/step\n",
      "Epoch 12/50\n",
      "469/469 - 3s - loss: 0.0012 - accuracy: 0.9937 - val_loss: 0.0032 - val_accuracy: 0.9790 - 3s/epoch - 5ms/step\n",
      "Epoch 13/50\n",
      "469/469 - 3s - loss: 0.0011 - accuracy: 0.9937 - val_loss: 0.0034 - val_accuracy: 0.9782 - 3s/epoch - 5ms/step\n",
      "Epoch 14/50\n",
      "469/469 - 3s - loss: 9.3179e-04 - accuracy: 0.9952 - val_loss: 0.0030 - val_accuracy: 0.9807 - 3s/epoch - 5ms/step\n",
      "Epoch 15/50\n",
      "469/469 - 3s - loss: 7.4588e-04 - accuracy: 0.9963 - val_loss: 0.0031 - val_accuracy: 0.9802 - 3s/epoch - 5ms/step\n",
      "Epoch 16/50\n",
      "469/469 - 3s - loss: 7.1450e-04 - accuracy: 0.9963 - val_loss: 0.0030 - val_accuracy: 0.9810 - 3s/epoch - 5ms/step\n",
      "Epoch 17/50\n",
      "469/469 - 3s - loss: 5.7820e-04 - accuracy: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9819 - 3s/epoch - 5ms/step\n",
      "Epoch 18/50\n",
      "469/469 - 3s - loss: 6.1610e-04 - accuracy: 0.9967 - val_loss: 0.0029 - val_accuracy: 0.9810 - 3s/epoch - 5ms/step\n",
      "Epoch 19/50\n",
      "469/469 - 3s - loss: 5.4163e-04 - accuracy: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9810 - 3s/epoch - 5ms/step\n",
      "Epoch 20/50\n",
      "469/469 - 3s - loss: 4.4359e-04 - accuracy: 0.9978 - val_loss: 0.0034 - val_accuracy: 0.9781 - 3s/epoch - 5ms/step\n",
      "Epoch 21/50\n",
      "469/469 - 3s - loss: 5.1402e-04 - accuracy: 0.9974 - val_loss: 0.0030 - val_accuracy: 0.9805 - 3s/epoch - 6ms/step\n",
      "Epoch 22/50\n",
      "469/469 - 3s - loss: 3.9265e-04 - accuracy: 0.9981 - val_loss: 0.0029 - val_accuracy: 0.9798 - 3s/epoch - 5ms/step\n",
      "Epoch 23/50\n",
      "469/469 - 3s - loss: 3.2493e-04 - accuracy: 0.9984 - val_loss: 0.0030 - val_accuracy: 0.9808 - 3s/epoch - 5ms/step\n",
      "Epoch 24/50\n",
      "469/469 - 3s - loss: 3.9639e-04 - accuracy: 0.9980 - val_loss: 0.0035 - val_accuracy: 0.9783 - 3s/epoch - 6ms/step\n",
      "Epoch 25/50\n",
      "469/469 - 3s - loss: 4.9075e-04 - accuracy: 0.9974 - val_loss: 0.0030 - val_accuracy: 0.9817 - 3s/epoch - 5ms/step\n",
      "Epoch 26/50\n",
      "469/469 - 3s - loss: 3.3761e-04 - accuracy: 0.9984 - val_loss: 0.0029 - val_accuracy: 0.9816 - 3s/epoch - 5ms/step\n",
      "Epoch 27/50\n",
      "469/469 - 3s - loss: 2.8934e-04 - accuracy: 0.9985 - val_loss: 0.0031 - val_accuracy: 0.9807 - 3s/epoch - 6ms/step\n",
      "Epoch 28/50\n",
      "469/469 - 3s - loss: 4.1283e-04 - accuracy: 0.9977 - val_loss: 0.0037 - val_accuracy: 0.9757 - 3s/epoch - 6ms/step\n",
      "Epoch 29/50\n",
      "469/469 - 3s - loss: 2.8398e-04 - accuracy: 0.9985 - val_loss: 0.0028 - val_accuracy: 0.9820 - 3s/epoch - 5ms/step\n",
      "Epoch 30/50\n",
      "469/469 - 3s - loss: 2.6520e-04 - accuracy: 0.9986 - val_loss: 0.0030 - val_accuracy: 0.9807 - 3s/epoch - 6ms/step\n",
      "Epoch 31/50\n",
      "469/469 - 3s - loss: 3.8641e-04 - accuracy: 0.9978 - val_loss: 0.0032 - val_accuracy: 0.9800 - 3s/epoch - 6ms/step\n",
      "Epoch 32/50\n",
      "469/469 - 3s - loss: 2.7594e-04 - accuracy: 0.9985 - val_loss: 0.0027 - val_accuracy: 0.9830 - 3s/epoch - 5ms/step\n",
      "Epoch 33/50\n",
      "469/469 - 3s - loss: 2.8962e-04 - accuracy: 0.9984 - val_loss: 0.0029 - val_accuracy: 0.9813 - 3s/epoch - 5ms/step\n",
      "Epoch 34/50\n",
      "469/469 - 3s - loss: 3.3927e-04 - accuracy: 0.9980 - val_loss: 0.0033 - val_accuracy: 0.9793 - 3s/epoch - 6ms/step\n",
      "Epoch 35/50\n",
      "469/469 - 3s - loss: 2.6898e-04 - accuracy: 0.9985 - val_loss: 0.0030 - val_accuracy: 0.9806 - 3s/epoch - 5ms/step\n",
      "Epoch 36/50\n",
      "469/469 - 3s - loss: 2.3509e-04 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9811 - 3s/epoch - 5ms/step\n",
      "Epoch 37/50\n",
      "469/469 - 3s - loss: 1.9011e-04 - accuracy: 0.9991 - val_loss: 0.0030 - val_accuracy: 0.9814 - 3s/epoch - 6ms/step\n",
      "Epoch 38/50\n",
      "469/469 - 3s - loss: 1.9849e-04 - accuracy: 0.9989 - val_loss: 0.0029 - val_accuracy: 0.9816 - 3s/epoch - 5ms/step\n",
      "Epoch 39/50\n",
      "469/469 - 3s - loss: 2.8237e-04 - accuracy: 0.9984 - val_loss: 0.0031 - val_accuracy: 0.9811 - 3s/epoch - 5ms/step\n",
      "Epoch 40/50\n",
      "469/469 - 3s - loss: 3.3794e-04 - accuracy: 0.9983 - val_loss: 0.0029 - val_accuracy: 0.9817 - 3s/epoch - 5ms/step\n",
      "Epoch 41/50\n",
      "469/469 - 3s - loss: 1.8807e-04 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9817 - 3s/epoch - 6ms/step\n",
      "Epoch 42/50\n",
      "469/469 - 3s - loss: 2.2174e-04 - accuracy: 0.9988 - val_loss: 0.0030 - val_accuracy: 0.9807 - 3s/epoch - 5ms/step\n",
      "Epoch 43/50\n",
      "469/469 - 3s - loss: 1.7661e-04 - accuracy: 0.9991 - val_loss: 0.0029 - val_accuracy: 0.9817 - 3s/epoch - 5ms/step\n",
      "Epoch 44/50\n",
      "469/469 - 3s - loss: 2.5641e-04 - accuracy: 0.9986 - val_loss: 0.0033 - val_accuracy: 0.9797 - 3s/epoch - 5ms/step\n",
      "Epoch 45/50\n",
      "469/469 - 3s - loss: 3.1644e-04 - accuracy: 0.9982 - val_loss: 0.0029 - val_accuracy: 0.9821 - 3s/epoch - 6ms/step\n",
      "Epoch 46/50\n",
      "469/469 - 3s - loss: 2.0650e-04 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9806 - 3s/epoch - 5ms/step\n",
      "Epoch 47/50\n",
      "469/469 - 3s - loss: 2.2142e-04 - accuracy: 0.9988 - val_loss: 0.0039 - val_accuracy: 0.9764 - 3s/epoch - 5ms/step\n",
      "Epoch 48/50\n",
      "469/469 - 3s - loss: 2.5154e-04 - accuracy: 0.9986 - val_loss: 0.0031 - val_accuracy: 0.9805 - 3s/epoch - 6ms/step\n",
      "Epoch 49/50\n",
      "469/469 - 3s - loss: 2.2520e-04 - accuracy: 0.9987 - val_loss: 0.0031 - val_accuracy: 0.9809 - 3s/epoch - 5ms/step\n",
      "Epoch 50/50\n",
      "469/469 - 3s - loss: 2.0192e-04 - accuracy: 0.9990 - val_loss: 0.0029 - val_accuracy: 0.9817 - 3s/epoch - 5ms/step\n",
      "accuracy = 98.17000031471252\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential([\n",
    "    Dense(units=512, activation=\"tanh\", input_shape=(784,)),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "log_dir = \"logs/fit/mlp_Adam\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "mlp.compile(loss=\"MSE\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "mlp.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test), verbose=2,\n",
    "       callbacks=[tensorboard_callback])\n",
    "\n",
    "res = mlp.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"accuracy =\", res[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d52347c-4e0d-41ba-8e89-5993b488b010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e6f982-5bb4-48fc-99cb-e1086fbf960f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp.save(\"./saved_model/mlp_adam.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd1195-0470-4f9b-a7d1-72e8e6ca7e0c",
   "metadata": {},
   "source": [
    "## 7.8 우편번호 인식기 v.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5a0f03-a820-4c83-a6b9-bf193c810b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./saved_model/mlp_adam.h5\")\n",
    "\n",
    "def reset():\n",
    "    global img\n",
    "    img = np.ones((200, 520, 3), dtype=np.uint8) * 255\n",
    "    for i in range(5):\n",
    "        cv2.rectangle(img, (10 + i * 100, 50), (10 + (i + 1) * 100, 150), (0, 0, 255))\n",
    "    cv2.putText(img, \"e:erase s:show r:recognition q:quit\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 1)\n",
    "    \n",
    "def grab_numerals():\n",
    "    numerals = []\n",
    "    for i in range(5):\n",
    "        roi = img[51:149, 11+i*100:9+(i+1)*100, 0]\n",
    "        roi = 255 - cv2.resize(roi, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "        numerals.append(roi)\n",
    "    numerals = np.array(numerals)\n",
    "    return numerals\n",
    "\n",
    "def show():\n",
    "    numerals = grab_numerals()\n",
    "    plt.figure(figsize=(25, 5))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(numerals[i], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def recognition():\n",
    "    numerals = grab_numerals()\n",
    "    numerals = numerals.reshape(5, 784)\n",
    "    numerals = numerals.astype(np.float32) / 255.0\n",
    "    res = model.predict(numerals)\n",
    "    class_id = np.argmax(res, axis=1)\n",
    "    for i in range(5):\n",
    "        cv2.putText(img, str(class_id[i]), (50+i*100, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1)\n",
    "    winsound.Beep(1000, 500)\n",
    "    \n",
    "brush_size = 4\n",
    "l_color = (0, 0, 0)\n",
    "\n",
    "def writing(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img, (x,y), brush_size, l_color, -1)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        cv2.circle(img, (x,y), brush_size, l_color, -1)\n",
    "        \n",
    "reset()\n",
    "cv2.namedWindow(\"Writing\")\n",
    "cv2.setMouseCallback(\"Writing\", writing)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Writing\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('e'):\n",
    "        reset()\n",
    "    elif key == ord('s'):\n",
    "        show()\n",
    "    elif key == ord('r'):\n",
    "        recognition()\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a91f2c-366e-4be6-9aab-302cedd5d684",
   "metadata": {},
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6684f2d9-34a9-4d60-8022-ea3dcc7b1df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nk를 늘릴 수록 모델의 신뢰도는 향상 됨\\n다만 시간이 늘어남\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 1\n",
    "'''\n",
    "k를 늘릴 수록 모델의 신뢰도는 향상 됨\n",
    "다만 시간이 늘어남\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea263f4-2f21-4c89-88f8-57b821872b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nor 문제를 해결할 수 있는 decision boundary는 무수히 많다.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 2\n",
    "'''\n",
    "or 문제를 해결할 수 있는 decision boundary는 무수히 많다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a1c1d-dc84-4ea7-8f89-c052adc01565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f90095f9-dfeb-4b3f-ad6b-67dae2fdc448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.] [1.] [1.] [-1.]\n"
     ]
    }
   ],
   "source": [
    "# 문제 4\n",
    "def tau(x):\n",
    "    return np.where(x > 0, 1., -1.)\n",
    "\n",
    "w1 = np.array([[-0.5, 1., 1.],\n",
    "              [1.5, -1., -1.]])\n",
    "w2 = np.array([[-1., 1., 1.]])\n",
    "forward = lambda x: tau(w2 @ np.append([1.], tau(w1 @ x.T)))\n",
    "\n",
    "check1 = forward(np.array([1, 0, 0]))\n",
    "check2 = forward(np.array([1, 1, 0]))\n",
    "check3 = forward(np.array([1, 0, 1]))\n",
    "check4 = forward(np.array([1, 1, 1]))\n",
    "print(check1, check2, check3, check4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a6b89f8-a61a-4656-8da6-b1440bf62cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.] [-1.] [-1.] [-1.]\n"
     ]
    }
   ],
   "source": [
    "# 문제 5\n",
    "w1 = np.array([[0.5, -1., 1.],\n",
    "              [-1.5, 1., -1.]])\n",
    "w2 = np.array([[-1., 1., 1.]])\n",
    "forward = lambda x: tau(w2 @ np.append([1.], tau(w1 @ x.T)))\n",
    "check1 = forward(np.array([1, 0, 0]))\n",
    "check2 = forward(np.array([1, 1, 0]))\n",
    "check3 = forward(np.array([1, 0, 1]))\n",
    "check4 = forward(np.array([1, 1, 1]))\n",
    "print(check1, check2, check3, check4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1b15a3b-a749-4090-ba9f-660a85c41924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7295104000000001\n"
     ]
    }
   ],
   "source": [
    "# 문제 6\n",
    "u = 0.8\n",
    "x = 0.2\n",
    "y = 1\n",
    "p = 0.1\n",
    "def der(x, y, u):\n",
    "    return 2 * (x)**2 * u - 2 * y * x\n",
    "\n",
    "for _ in range(3):\n",
    "    u = u - der(x, y, u)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f93334d-5f49-4560-a307-cf1f689a0572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDNN의 hyperparameter\\nnum_layer : layer의 수. layer 수가 늘어 날 수록 모델의 복잡도 상승. overfitting 위험성\\nnum_units : layer당 unit의 수. layer와 비슷\\noptimzer : 최적화 알고리즘. 그냥 Adam을 많이 쓴다.\\nloss_fn : loss function. 상황에 맞게 써야함.\\n그 외, BN의 beta, dropout rate, learning rate 등\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 7\n",
    "'''\n",
    "DNN의 hyperparameter\n",
    "num_layer : layer의 수. layer 수가 늘어 날 수록 모델의 복잡도 상승. overfitting 위험성\n",
    "num_units : layer당 unit의 수. layer와 비슷\n",
    "optimzer : 최적화 알고리즘. 그냥 Adam을 많이 쓴다.\n",
    "loss_fn : loss function. 상황에 맞게 써야함.\n",
    "그 외, BN의 beta, dropout rate, learning rate 등\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dce79f1e-3f5d-49f8-a481-f6f15a84a299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 97.99000024795532\n",
      "accuracy = 98.07999730110168\n",
      "accuracy = 98.14000129699707\n",
      "accuracy = 98.11999797821045\n",
      "accuracy = 98.28000068664551\n"
     ]
    }
   ],
   "source": [
    "# 문제 8\n",
    "for lr in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    mlp = Sequential([\n",
    "        Dense(units=512, activation=\"tanh\", input_shape=(784,)),\n",
    "        Dense(units=10, activation=\"softmax\")\n",
    "    ])\n",
    "    log_dir = \"logs/lr_fit/mlp_Adam_{}\".format(lr)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    mlp.compile(loss=\"MSE\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "    mlp.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test), verbose=0,\n",
    "           callbacks=[tensorboard_callback])\n",
    "\n",
    "    res = mlp.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"accuracy =\", res[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "072e254c-f48c-4ae5-a0c6-abd4a13f173d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkeras tuner : https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=ko\\nwandb : https://wandb.ai/site\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 9\n",
    "'''\n",
    "keras tuner : https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=ko\n",
    "wandb : https://wandb.ai/site\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cfbd4ad-e78b-44cd-ae5a-9d96d70562f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "# 문제 10\n",
    "model = tf.keras.models.load_model(\"./saved_model/mlp_adam.h5\")\n",
    "\n",
    "def reset():\n",
    "    global img\n",
    "    img = np.ones((200, 520, 3), dtype=np.uint8) * 255\n",
    "    for i in range(5):\n",
    "        cv2.rectangle(img, (10 + i * 100, 50), (10 + (i + 1) * 100, 150), (0, 0, 255))\n",
    "    cv2.putText(img, \"e:erase s:show r:recognition q:quit\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 1)\n",
    "    \n",
    "def grab_numerals():\n",
    "    numerals = []\n",
    "    for i in range(5):\n",
    "        roi = img[51:149, 11+i*100:9+(i+1)*100, 0]\n",
    "        roi = 255 - cv2.resize(roi, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "        numerals.append(roi)\n",
    "    numerals = np.array(numerals)\n",
    "    return numerals\n",
    "\n",
    "def show():\n",
    "    numerals = grab_numerals()\n",
    "    plt.figure(figsize=(25, 5))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(numerals[i], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def recognition():\n",
    "    numerals = grab_numerals()\n",
    "    numerals = numerals.reshape(5, 784)\n",
    "    numerals = numerals.astype(np.float32) / 255.0\n",
    "    res = model.predict(numerals)\n",
    "    class_id = np.argmax(res, axis=1)\n",
    "    second_id = np.argsort(res, axis=1)[..., -2]\n",
    "    for i in range(5):\n",
    "        cv2.putText(img, \"{}({})\".format(class_id[i], second_id[i]), (50+i*100, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1)\n",
    "    winsound.Beep(1000, 500)\n",
    "    \n",
    "brush_size = 4\n",
    "l_color = (0, 0, 0)\n",
    "\n",
    "def writing(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img, (x,y), brush_size, l_color, -1)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        cv2.circle(img, (x,y), brush_size, l_color, -1)\n",
    "        \n",
    "reset()\n",
    "cv2.namedWindow(\"Writing\")\n",
    "cv2.setMouseCallback(\"Writing\", writing)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Writing\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('e'):\n",
    "        reset()\n",
    "    elif key == ord('s'):\n",
    "        show()\n",
    "    elif key == ord('r'):\n",
    "        recognition()\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
